{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":267091,"sourceType":"datasetVersion","datasetId":111554}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv', encoding='latin')\ndf.head()","metadata":{"papermill":{"duration":0.603175,"end_time":"2022-11-10T19:24:41.493600","exception":false,"start_time":"2022-11-10T19:24:40.890425","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['attack_cat'].unique()","metadata":{"papermill":{"duration":0.029579,"end_time":"2022-11-10T19:24:41.530076","exception":false,"start_time":"2022-11-10T19:24:41.500497","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(unique, counts) = np.unique(df['attack_cat'], return_counts=True)\n\nprint('Unique values of the target variable', unique)\nprint('Counts of the target variable :', counts)","metadata":{"papermill":{"duration":0.067109,"end_time":"2022-11-10T19:24:41.604156","exception":false,"start_time":"2022-11-10T19:24:41.537047","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 8))\nplt.rcParams.update({'font.size': 14})\nax.set_xlabel('Time [s]', fontsize='large', fontweight='bold')\nax.set_ylabel('Time [s]', fontsize='large', fontweight='bold')\nplt.rc('xtick', labelsize=12)\nplt.rc('ytick', labelsize=12)\nax.bar(unique, counts)\nplt.show()","metadata":{"papermill":{"duration":0.205247,"end_time":"2022-11-10T19:24:42.165682","exception":false,"start_time":"2022-11-10T19:24:41.960435","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.replace(to_replace=[\"Analysis\"], value=\"Attacks_1\", inplace=True)\ndf.replace(to_replace=[\"Backdoor\"], value=\"Attacks_1\", inplace=True)\ndf.replace(to_replace=[\"Shellcode\"], value=\"Attacks_1\", inplace=True)\ndf.replace(to_replace=[\"Worms\"], value=\"Attacks_1\", inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['attack_cat'] != 'Attacks_1']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(unique, counts) = np.unique(df['attack_cat'], return_counts=True)\n\nprint('Unique values of the target variable', unique)\nprint('Counts of the target variable :', counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n# Converting string labels into numbers. \ndf.iloc[:,4] = le.fit_transform(df.iloc[:,4]).astype('float64')\ndf.iloc[:,2] = le.fit_transform(df.iloc[:,2]).astype('float64')\ndf.iloc[:,3] = le.fit_transform(df.iloc[:,3]).astype('float64')\ndf.iloc[:,43] = le.fit_transform(df.iloc[:,43]).astype('float64')\n\ndf.isnull().sum()","metadata":{"papermill":{"duration":0.115451,"end_time":"2022-11-10T19:24:42.289091","exception":false,"start_time":"2022-11-10T19:24:42.173640","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df.drop(['label', 'attack_cat', 'ï»¿id'], axis = 1)\n\ny_train = df['attack_cat']\n\nX_train.shape, y_train.shape","metadata":{"papermill":{"duration":0.031163,"end_time":"2022-11-10T19:24:42.361510","exception":false,"start_time":"2022-11-10T19:24:42.330347","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=pd.read_csv('../input/unsw-nb15/UNSW_NB15_testing-set.csv', encoding='latin')\n\ndf_test.head()","metadata":{"papermill":{"duration":1.134742,"end_time":"2022-11-10T19:24:43.504284","exception":false,"start_time":"2022-11-10T19:24:42.369542","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['attack_cat'].unique()","metadata":{"papermill":{"duration":0.032508,"end_time":"2022-11-10T19:24:43.546667","exception":false,"start_time":"2022-11-10T19:24:43.514159","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(unique, counts) = np.unique(df_test['attack_cat'], return_counts=True)\n\nprint('Unique values of the target variable', unique)\nprint('Counts of the target variable :', counts)","metadata":{"papermill":{"duration":0.137105,"end_time":"2022-11-10T19:24:43.691848","exception":false,"start_time":"2022-11-10T19:24:43.554743","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 8))\nplt.rcParams.update({'font.size': 14})\nax.set_xlabel('Time [s]', fontsize='large', fontweight='bold')\nax.set_ylabel('Time [s]', fontsize='large', fontweight='bold')\nplt.rc('xtick', labelsize=12)\nplt.rc('ytick', labelsize=15)\nax.bar(unique, counts)\nplt.show()","metadata":{"papermill":{"duration":0.185244,"end_time":"2022-11-10T19:24:44.563972","exception":false,"start_time":"2022-11-10T19:24:44.378728","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.replace(to_replace=[\"Analysis\"], value=\"Attacks_1\", inplace=True)\ndf_test.replace(to_replace=[\"Backdoor\"], value=\"Attacks_1\", inplace=True)\ndf_test.replace(to_replace=[\"Shellcode\"], value=\"Attacks_1\", inplace=True)\ndf_test.replace(to_replace=[\"Worms\"], value=\"Attacks_1\", inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = df_test[df_test['attack_cat'] != 'Attacks_1']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n# Converting string labels into numbers. \ndf_test.iloc[:,4] = le.fit_transform(df_test.iloc[:,4]).astype('float64')\ndf_test.iloc[:,2] = le.fit_transform(df_test.iloc[:,2]).astype('float64')\ndf_test.iloc[:,3] = le.fit_transform(df_test.iloc[:,3]).astype('float64')\ndf_test.iloc[:,43] = le.fit_transform(df_test.iloc[:,43]).astype('float64')\n\ndf_test.isnull().sum()","metadata":{"papermill":{"duration":0.212101,"end_time":"2022-11-10T19:24:44.784870","exception":false,"start_time":"2022-11-10T19:24:44.572769","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = df_test.drop(['label', 'attack_cat', 'ï»¿id'], axis = 1)\n\ny_test = df_test['attack_cat']\n\nX_test.shape, y_test.shape","metadata":{"papermill":{"duration":0.034188,"end_time":"2022-11-10T19:24:44.876423","exception":false,"start_time":"2022-11-10T19:24:44.842235","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bi_train_y = y_train.copy()\nprint(bi_train_y.unique())\n\nbi_test_y = y_test.copy()\nprint(bi_test_y.unique())\n\n### switch for binary!\ny_train = bi_train_y\ny_test = bi_test_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### transform ndarray back:\nX_train = X_train.values\nX_test = X_test.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### reshape input data to LSTM format [samples, time_steps, features]\nX_train_lstm = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\nX_test_lstm = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\nprint(f\"shape of X_train:\", X_train_lstm.shape)\nprint(f\"shape of X_test:\", X_test_lstm.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_lstm = X_train_lstm[:, None, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshaping X_train for efficient modelling\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multiClassModel(N):\n    model = Sequential()\n    model.add(GRU(units=N, return_sequences=True, input_shape=(X_train.shape[1],1)))\n    model.add(Dropout(0.2))\n    # Second LSTM layer\n    model.add(GRU(units=50, return_sequences=True))\n    model.add(Dropout(0.2))\n    # Third LSTM layer\n    model.add(GRU(units=50, return_sequences=True))\n    model.add(Dropout(0.2))\n    # Fourth LSTM layer\n    model.add(GRU(units=50))\n    model.add(Dropout(0.2))\n    # The output layer\n    model.add(Dense(units=6, activation=\"softmax\", name=\"softmax\"))\n\n    model.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    model.summary()\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend\n\nN= len(df.columns)\n# from keras.callbacks import EarlyStopping\ncallback = EarlyStopping(patience=20, mode='min', restore_best_weights=True)\nbackend.clear_session()\nmodel = multiClassModel(N)\nhistory = model.fit(X_train,y_train,epochs=30,batch_size=64, callbacks=[callback])\n### check the loss trend of epochs\npd.DataFrame(history.history).plot(kind='line', xlabel='epochs', figsize=(8, 6))\n\nimport matplotlib.pyplot as plt\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting on training set\ny_train_pred_prob = model.predict(X_train)\ny_test_pred_prob = model.predict(X_test)\ny_train_pred = np.argmax(y_train_pred_prob, axis=1)\ny_test_pred = np.argmax(y_test_pred_prob, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nlabels=le.classes_\n\ncm = confusion_matrix(y_train, y_train_pred)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.rcParams.update({'font.size': 15})\nax.set_xlabel('Time [s]', fontsize='large', fontweight='bold')\nax.set_ylabel('Time [s]', fontsize='large', fontweight='bold')\n#ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_).plot(ax=ax)\nax= plt.subplot();\nsns.heatmap(cm, annot=True, fmt='g', ax=ax, xticklabels=labels, yticklabels=labels, cmap='Blues')\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=le.classes_\n\ncm = confusion_matrix(y_test, y_test_pred)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.rcParams.update({'font.size': 15})\nax.set_xlabel('Time [s]', fontsize='large', fontweight='bold')\nax.set_ylabel('Time [s]', fontsize='large', fontweight='bold')\n#ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_).plot(ax=ax)\nax= plt.subplot();\nsns.heatmap(cm, annot=True, fmt='g', ax=ax, xticklabels=labels, yticklabels=labels, cmap='Blues')\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multilabel_matrix(y_true, y_pred, labels=None):\n    mlm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n    df_performance = pd.DataFrame(index=labels, columns=['accuracy', 'precision', 'recall', 'f1_score', 'FPR'])\n    for i, label in enumerate(labels):\n        tn, fp, fn, tp = mlm[i].ravel()\n        accuracy = (tn + tp) / (tn + fp + fn + tp)\n        precision = tp / (tp + fp)\n        recall = tp / (tp + fn)\n        fpr = fp / (tn + fp)\n\n        f1_score = 2*precision * recall / (precision + recall)\n        df_performance.loc[label] = [round(accuracy, 4), round(precision,4), \\\n                                     round(recall, 4), round(f1_score,4), round(fpr,4)]\n    return df_performance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def FPR(y_true, y_pred, labels=None):\n    mlm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n    df_performance = pd.DataFrame(index=labels, columns=['FPR'])\n    for i, label in enumerate(labels):\n        tn, fp, fn, tp = mlm[i].ravel()\n        specificity = (tn) / (tn + fp)\n        \n        df_performance.loc[label] = 1 - specificity\n    \n    return df_performance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nfrom itertools import cycle\ndef RoC_Curve(y_score, y, labels, title): \n    y_cat = to_categorical(y)\n    \n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    lw = 2\n    # First aggregate all false positive rates\n    n_classes = len(labels)\n#     print('n_classes:', n_classes)\n\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_cat[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_cat.ravel(), y_score.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(n_classes):\n        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n    # Finally average it and compute AUC\n    mean_tpr /= n_classes\n\n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n    # Plot all ROC curves\n    plt.figure(figsize=(8, 8))\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC curve (area = {0:0.4f})'\n                   ''.format(roc_auc[\"micro\"]),\n             color='deeppink', linestyle=':', linewidth=4)\n\n    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n             label='macro-average ROC curve (area = {0:0.4f})'\n                   ''.format(roc_auc[\"macro\"]),\n             color='navy', linestyle=':', linewidth=4)\n           \n    for i in range(n_classes):\n        plt.plot(fpr[i], tpr[i], lw=lw,\n                 label=f'ROC curve of class {labels[i]} (area = {roc_auc[i]:0.4f})')\n\n       \n    plt.rcParams.update({'font.size': 11})    \n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([-0.1, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(title, fontsize=16)\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_no = np.unique(y_train)\nprint(y_no)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le.classes_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, multilabel_confusion_matrix\n\nprint(classification_report(y_test, y_test_pred))\n\nperformance = multilabel_matrix(y_test, y_test_pred, labels=y_no)\nperformance['Attack'] = le.classes_\n\nperformance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance = FPR(y_test, y_test_pred, labels=y_no)\nperformance['Attack'] = le.classes_\n\nperformance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.unique(y_train, return_counts=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.unique(y_train[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RoC_Curve(y_test_pred_prob, y_test, le.classes_, title='ROC for test set')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def GWO(objf,lb,ub,dim,SearchAgents_no,Max_iter):\n    \n    # initialize alpha, beta, and delta_pos\n    Alpha_pos=np.zeros(dim)\n    Alpha_score=float(\"inf\")\n    \n    Beta_pos=np.zeros(dim)\n    Beta_score=float(\"inf\")\n    \n    Delta_pos=np.zeros(dim)\n    Delta_score=float(\"inf\")\n\n    if not isinstance(lb, list):\n        lb = [lb] * dim\n    if not isinstance(ub, list):\n        ub = [ub] * dim\n    \n    #Initialize the positions of search agents\n    Positions = np.zeros((SearchAgents_no, dim))\n    for i in range(dim):\n        Positions[:, i] = np.random.uniform(0,1, SearchAgents_no) * (ub[i] - lb[i]) + lb[i]\n    \n    Convergence_curve=np.zeros(Max_iter)\n\n     # Loop counter\n    print(\"GWO is optimizing  \\\"\"+objf.__name__+\"\\\"\")    \n\n    # Main loop\n    for l in range(0,Max_iter):\n        for i in range(0,SearchAgents_no):\n            \n            # Return back the search agents that go beyond the boundaries of the search space\n            for j in range(dim):\n                Positions[i,j]=np.clip(Positions[i,j], lb[j], ub[j])\n\n            # Calculate objective function for each search agent\n            fitness=objf(Positions[i,:])\n            \n            # Update Alpha, Beta, and Delta\n            if fitness<Alpha_score :\n                Alpha_score=fitness; # Update alpha\n                Alpha_pos=Positions[i,:].copy()\n            \n            \n            if (fitness>Alpha_score and fitness<Beta_score ):\n                Beta_score=fitness  # Update beta\n                Beta_pos=Positions[i,:].copy()\n            \n            \n            if (fitness>Alpha_score and fitness>Beta_score and fitness<Delta_score): \n                Delta_score=fitness # Update delta\n                Delta_pos=Positions[i,:].copy()\n        \n        a=2-l*((2)/Max_iter); # a decreases linearly fron 2 to 0\n        \n        # Update the Position of search agents including omegas\n        for i in range(0,SearchAgents_no):\n            for j in range (0,dim):     \n                           \n                r1=random.random() # r1 is a random number in [0,1]\n                r2=random.random() # r2 is a random number in [0,1]\n                \n                A1=2*a*r1-a; # Equation (3.3)\n                C1=2*r2; # Equation (3.4)\n                \n                D_alpha=abs(C1*Alpha_pos[j]-Positions[i,j]); # Equation (3.5)-part 1\n                X1=Alpha_pos[j]-A1*D_alpha; # Equation (3.6)-part 1\n                           \n                r1=random.random()\n                r2=random.random()\n                \n                A2=2*a*r1-a; # Equation (3.3)\n                C2=2*r2; # Equation (3.4)\n                \n                D_beta=abs(C2*Beta_pos[j]-Positions[i,j]); # Equation (3.5)-part 2\n                X2=Beta_pos[j]-A2*D_beta; # Equation (3.6)-part 2       \n                \n                r1=random.random()\n                r2=random.random() \n                \n                A3=2*a*r1-a; # Equation (3.3)\n                C3=2*r2; # Equation (3.4)\n                \n                D_delta=abs(C3*Delta_pos[j]-Positions[i,j]); # Equation (3.5)-part 3\n                X3=Delta_pos[j]-A3*D_delta; # Equation (3.5)-part 3             \n                \n                Positions[i,j]=(X1+X2+X3)/3  # Equation (3.7)        \n        Convergence_curve[l]=Alpha_score;\n\n        #if (l%1==0):\n               #print(['At iteration '+ str(l)+ ' the best fitness is '+ str(Alpha_score)]);\n    \n    print(Positions.shape)\n    print(\"Alpha position=\",Alpha_pos);\n    print(\"Beta position=\",Beta_pos);\n    print(\"Delta position=\",Delta_pos);\n    return Alpha_pos,Beta_pos;","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/benchmarks/')\nimport benchmarks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\niters=1000\nwolves=200\ndimension=30\nsearch_domain=[0,1]\nlb=-5.28\nub=5.28\ncolneeded=[0,1,2,4,5,7,8,10,11,13,14]\nmodified_data=pd.DataFrame()\nfor i in colneeded:\n    modified_data[df.columns[i]]=df[df.columns[i]].astype(float)\nfunc_details=benchmarks.getFunctionDetails(6)\n\nfor i in range(0,10):\n    alpha,beta=GWO(getattr(benchmarks,'F7'),lb,ub,dimension,wolves,iters)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Applying feature selection on the given dataset\n##considering alpha as best solution and putting a threshold\nthreshold=-0.9\nindex=[]\nprint(\"alpha shape=\",alpha.shape[0])\nmodified_daata=pd.DataFrame();\nmodified_daata_test=pd.DataFrame();\nfor i in range(0,alpha.shape[0]):\n    if(alpha[i]>=threshold):\n        modified_daata[df.columns[i]]=df[df.columns[i]].astype(float)\n        modified_daata_test[df_test.columns[i]]=df_test[df_test.columns[i]].astype(float)\nprint(\"The modified data is following\")\nmodified_daata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modified_daata_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = modified_daata\ny_train = df['attack_cat'].values\n\nX_test = modified_daata_test\ny_test = df_test['attack_cat'].values\n\n#X_train, X_test, y_train, y_test = train_test_split(modified_daata, Y, test_size = 0.40, random_state = 14)\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.transform(X_test)\n#print(X_train[0])\nmodified_daata.info()\nmodified_daata_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshaping X_train for efficient modelling\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import backend\n\nN= len(modified_daata.columns)\n# from keras.callbacks import EarlyStopping\ncallback = EarlyStopping(patience=20, mode='min', restore_best_weights=True)\nbackend.clear_session()\nmodel = multiClassModel(N)\nhistory = model.fit(X_train,y_train,epochs=30,batch_size=64, callbacks=[callback])\n### check the loss trend of epochs\npd.DataFrame(history.history).plot(kind='line', xlabel='epochs', figsize=(8, 6))\n\nimport matplotlib.pyplot as plt\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting on training set\ny_train_pred_prob = model.predict(X_train)\ny_test_pred_prob = model.predict(X_test)\ny_train_pred = np.argmax(y_train_pred_prob, axis=1)\ny_test_pred = np.argmax(y_test_pred_prob, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nlabels=le.classes_\n\ncm = confusion_matrix(y_train, y_train_pred)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.rcParams.update({'font.size': 15})\nax.set_xlabel('Time [s]', fontsize='large', fontweight='bold')\nax.set_ylabel('Time [s]', fontsize='large', fontweight='bold')\n#ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_).plot(ax=ax)\nax= plt.subplot();\nsns.heatmap(cm, annot=True, fmt='g', ax=ax, xticklabels=labels, yticklabels=labels, cmap='Blues')\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_test_pred)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.rcParams.update({'font.size': 15})\nax.set_xlabel('Time [s]', fontsize='large', fontweight='bold')\nax.set_ylabel('Time [s]', fontsize='large', fontweight='bold')\n#ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_).plot(ax=ax)\nax= plt.subplot();\nsns.heatmap(cm, annot=True, fmt='g', ax=ax, xticklabels=labels, yticklabels=labels, cmap='Blues')\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, multilabel_confusion_matrix\n\nprint(classification_report(y_test, y_test_pred))\n#performance = multilabel_matrix(y_train_pred, y_train, labels=y_test)\n#performance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.unique(y_train, return_counts=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, multilabel_confusion_matrix\n\nprint(classification_report(y_test, y_test_pred))\n\nperformance = multilabel_matrix(y_test, y_test_pred, labels=y_no)\nperformance['Attack'] = le.classes_\n\nperformance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RoC_Curve(y_train_pred_prob, y_train, le.classes_, title='ROC for UNSW-NB15 training set')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RoC_Curve(y_test_pred_prob, y_test, le.classes_, title='ROC for UNSW-NB15 test set')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}